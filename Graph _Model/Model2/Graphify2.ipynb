{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Graphs from JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text_file_as_set(file_path):\n",
    "    \"\"\"\n",
    "    Load a text file and return a set where each line is an element of the set.\n",
    "    \n",
    "    :param file_path: Path to the text file\n",
    "    :return: A set containing lines from the text file\n",
    "    \"\"\"\n",
    "    result_set = set()\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                result_set.add(line.strip())\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {file_path}: {e}\")\n",
    "    return result_set\n",
    "\n",
    "# Example usage\n",
    "file_path = '/workspace/JSONs/Capturing-logs/unique_sysnames_procnames.txt'\n",
    "loaded_set = load_text_file_as_set(file_path)\n",
    "print(loaded_set)\n",
    "print(len(loaded_set))  # Number of elements in the set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Define root directory, categories with labels, and output directory for saved graphs\n",
    "root_dir = '/workspace/JSONs/Capturing-logs'\n",
    "output_dir = '/workspace/Dynamic 2/ProcessedGraphs'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "categories = {\n",
    "    \"AdwareJsonMini\": 1,\n",
    "    \"BankingJsonMini\": 1,\n",
    "    \"BenignJsonMini\": 0,\n",
    "    \"RiskWareJsonMini\": 1,\n",
    "    \"SmsJsonMini\": 1\n",
    "}\n",
    "\n",
    "# Load unique sysnames from file into a set\n",
    "file_path = '/workspace/JSONs/Capturing-logs/unique_sysnames_procnames.txt'\n",
    "loaded_set = set()\n",
    "try:\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            loaded_set.add(line.strip())\n",
    "except Exception as e:\n",
    "    print(f\"Error reading file {file_path}: {e}\")\n",
    "\n",
    "# Integer encoding dictionary for sysnames with a fallback for unknown sysnames\n",
    "sysname_encoder = {name: i for i, name in enumerate(loaded_set)}\n",
    "sysname_encoder[\"UNKNOWN\"] = -1  # Assign -1 to unknown sysnames\n",
    "\n",
    "def parse_json_to_graph(file_path, label, save_path):\n",
    "    try:\n",
    "        with open(file_path) as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # Initialize node features and edges\n",
    "        node_features = []\n",
    "        edges = []\n",
    "\n",
    "        # Extract syscall information\n",
    "        syscalls = data.get('behaviors', {}).get('dynamic', {}).get('host', [])\n",
    "        for i, syscall in enumerate(syscalls):\n",
    "            syscall_info = syscall.get('low', [{}])[0]\n",
    "\n",
    "            # Retrieve 'sysname' or use \"UNKNOWN\" if not available\n",
    "            sysname = syscall_info.get('sysname', 'UNKNOWN')\n",
    "            sysname_index = sysname_encoder.get(sysname, sysname_encoder['UNKNOWN'])  # Integer encoding\n",
    "\n",
    "            # Add the integer-encoded sysname as a feature\n",
    "            feature_vector = [sysname_index]\n",
    "            node_features.append(feature_vector)\n",
    "\n",
    "            # Sequential edge\n",
    "            if i > 0:\n",
    "                edges.append([i - 1, i])\n",
    "\n",
    "            # Cross-reference edge using 'xref'\n",
    "            if 'xref' in syscall_info:\n",
    "                xref_id = syscall_info['xref']\n",
    "                if xref_id < i:  # Ensure valid reference\n",
    "                    edges.append([xref_id, i])\n",
    "\n",
    "        # Skip saving if no valid syscalls\n",
    "        if not node_features:\n",
    "            print(f\"No valid syscalls with 'sysname' found in file: {file_path}\")\n",
    "            return\n",
    "\n",
    "        # Convert node features and edges to PyTorch tensors\n",
    "        x = torch.tensor(node_features, dtype=torch.float)\n",
    "        edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "\n",
    "        # Create Data object\n",
    "        graph_data = Data(x=x, edge_index=edge_index, y=torch.tensor([label], dtype=torch.long))\n",
    "\n",
    "        # Save graph data as .pt file\n",
    "        torch.save(graph_data, save_path)\n",
    "        print(f\"Saved graph to {save_path}\")\n",
    "\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Skipping file due to JSONDecodeError: {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file_path}: {e}\")\n",
    "\n",
    "# Process each file in categories and save immediately to prevent memory overload\n",
    "for category, label in categories.items():\n",
    "    category_dir = os.path.join(root_dir, category)\n",
    "    for file_name in os.listdir(category_dir):\n",
    "        if file_name.endswith('.json'):\n",
    "            file_path = os.path.join(category_dir, file_name)\n",
    "            save_path = os.path.join(output_dir, f\"{category}_{file_name.replace('.json', '.pt')}\")\n",
    "            parse_json_to_graph(file_path, label, save_path)\n",
    "\n",
    "print(\"All graphs have been processed and saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

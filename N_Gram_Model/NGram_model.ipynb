{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-07 16:51:14.043438: E external/local_xla/xla/stream_executor/plugin_registry.cc:91] Invalid plugin kind specified: FFT\n",
      "2024-11-07 16:51:14.073812: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 16:51:14.345439: E external/local_xla/xla/stream_executor/plugin_registry.cc:91] Invalid plugin kind specified: DNN\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.20) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "/usr/local/lib/python3.9/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.9951\n",
      "\n",
      "Report for AdwareJson:\n",
      "  Precision: 1.0000\n",
      "  Recall:    0.9962\n",
      "  F1-Score:  0.9981\n",
      "  Support:   782.0\n",
      "\n",
      "Report for BankingwareJson:\n",
      "  Precision: 0.9987\n",
      "  Recall:    0.9937\n",
      "  F1-Score:  0.9962\n",
      "  Support:   794.0\n",
      "\n",
      "Report for BenignJson:\n",
      "  Precision: 0.9871\n",
      "  Recall:    0.9948\n",
      "  F1-Score:  0.9910\n",
      "  Support:   772.0\n",
      "\n",
      "Report for RiskwareJson:\n",
      "  Precision: 0.9896\n",
      "  Recall:    0.9974\n",
      "  F1-Score:  0.9935\n",
      "  Support:   765.0\n",
      "\n",
      "Report for SmswareJson:\n",
      "  Precision: 1.0000\n",
      "  Recall:    0.9937\n",
      "  F1-Score:  0.9968\n",
      "  Support:   791.0\n",
      "\n",
      "Macro Average:\n",
      "  Precision: 0.9951\n",
      "  Recall:    0.9951\n",
      "  F1-Score:  0.9951\n",
      "\n",
      "Weighted Average:\n",
      "  Precision: 0.9952\n",
      "  Recall:    0.9951\n",
      "  F1-Score:  0.9951\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load and combine data from multiple CSV files\n",
    "def load_data(file_paths):\n",
    "    data = []\n",
    "    labels = []\n",
    "    max_features = 0\n",
    "    file_data = []\n",
    "\n",
    "    # First pass: Read all files and find the maximum number of feature columns\n",
    "    for file_path in file_paths:\n",
    "        with open(file_path, 'r') as f:\n",
    "            reader = csv.reader(f)\n",
    "            header = next(reader)\n",
    "\n",
    "            # Identify the \"malware_type\" column\n",
    "            malware_type_index = header.index(\"malware_type\")\n",
    "\n",
    "            for row in reader:\n",
    "                label = row[malware_type_index]\n",
    "                features = [\n",
    "                    float(val) if val else 0.0\n",
    "                    for i, val in enumerate(row) if i != malware_type_index\n",
    "                ]\n",
    "                max_features = max(max_features, len(features))\n",
    "                file_data.append((features, label))\n",
    "\n",
    "    # Second pass: Pad rows to max_features length\n",
    "    data, labels = [], []\n",
    "    for features, label in file_data:\n",
    "        if len(features) < max_features:\n",
    "            features += [0.0] * (max_features - len(features))\n",
    "        data.append(features)\n",
    "        labels.append(label)\n",
    "    \n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "# Define file paths\n",
    "file_paths = [\n",
    "    \"/workspace/Ngram2/AdwareJson.csv\",\n",
    "    \"/workspace/Ngram2/BenignJson.csv\",\n",
    "    \"/workspace/Ngram2/BankingwareJson.csv\",\n",
    "    \"/workspace/Ngram2/RiskwareJson.csv\",\n",
    "    \"/workspace/Ngram2/SmswareJson.csv\"\n",
    "]\n",
    "\n",
    "# Load data\n",
    "X, y = load_data(file_paths)\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Balance the classes using Random Oversampling\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y_encoded)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred, target_names=label_encoder.classes_, output_dict=True)\n",
    "\n",
    "# Print overall accuracy\n",
    "print(f\"Overall Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Print detailed report for each malware type\n",
    "for malware_type, metrics in report.items():\n",
    "    if malware_type in label_encoder.classes_:  # Skip 'accuracy', 'macro avg', 'weighted avg' keys\n",
    "        print(f\"\\nReport for {malware_type}:\")\n",
    "        print(f\"  Precision: {metrics['precision']:.4f}\")\n",
    "        print(f\"  Recall:    {metrics['recall']:.4f}\")\n",
    "        print(f\"  F1-Score:  {metrics['f1-score']:.4f}\")\n",
    "        print(f\"  Support:   {metrics['support']}\")\n",
    "        \n",
    "# Print macro and weighted averages\n",
    "print(\"\\nMacro Average:\")\n",
    "print(f\"  Precision: {report['macro avg']['precision']:.4f}\")\n",
    "print(f\"  Recall:    {report['macro avg']['recall']:.4f}\")\n",
    "print(f\"  F1-Score:  {report['macro avg']['f1-score']:.4f}\")\n",
    "\n",
    "print(\"\\nWeighted Average:\")\n",
    "print(f\"  Precision: {report['weighted avg']['precision']:.4f}\")\n",
    "print(f\"  Recall:    {report['weighted avg']['recall']:.4f}\")\n",
    "print(f\"  F1-Score:  {report['weighted avg']['f1-score']:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
